# ????????????????????????????????????????????????????????????????????????????????
# Running the same tests with LiteLLM
# ????????????????????????????????????????????????????????????????????????????????

# --- Imports ---

import os

from dotenv import load_dotenv
from litellm import completion
from src.utz import header1

from .wm import save_to_markdown

# --- Load the envpussy --
load_dotenv("src/.env")
SA_T = os.getenv("SAO")

# --- Main File Function ---


def s2_file():
    lite1()


# === Sub Functions ===

# Litellm Example from docs
# https://docs.sambanova.ai/cloud/docs/integrations/litellm#litellm

def lite1():
    header1("LiteLLM Example from SN docs")

    os.environ['SAMBANOVA_API_KEY'] = SA_T

    response = completion(
        model="sambanova/Meta-Llama-3.2-3B-Instruct",
        messages=[
            {
                "role": "user",
                "content": "What does the term booty sniff dancing mean ?, answer like a gangster",
            }
        ],
        max_tokens=200,
        stop=[],
        temperature=0.2,
        top_p=0.9,
        user="user",
    )
    print(response.choices[0].message.content)
    save_to_markdown(
        response.choices[0].message.content,
        prefix="lite1",
        directory="rez"
    )
